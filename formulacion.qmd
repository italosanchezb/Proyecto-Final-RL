## Formulación

El Proceso de Decisión de Markov se compone de los siguientes elementos:

-   El conjunto de estados estará conformado por las siguientes tres divisiones del campo 

![](campo.png)

Donde $C_1,C_2,C_3$ representa que el balón se encuentre en alguna de las tres divisiones.

Además se agregan tres estados absorbentes:

-   $L_p =$ pérdida de posesión del balón.
-   $nG =$ realizar un tiro y que no termine en gol.
-   $G =$ realizar un tiro y que termine en gol.

De esta forma el conjunto de estados $\mathcal{S}$ queda como

$$
    \mathcal{S}=\{C_1,C_2,C_3,L_p,nG,G\}
$$

-   El conjunto de acciones admisibles se considerarán 3 acciones que serán

    -   $t$ = tiro
    -   $p$ = pase
    -   $r$ = regate

    De esta forma el conjunto de acciones queda como $$\mathcal{A} = \{t,p,r\}$$

-   Para las de transiciones haremos uso de las probabilidades de transición definidas de la siguiente forma: $$
     P:\mathcal{S}\times\mathcal{A}\times\mathcal{S} \to [0,1]
     $$

    Que se interpreta como la probabilidad de estar en un estado $S_i$ realizar una acción $a_k$ y terminar en un estado $S_j$. Notemos que se aceptan los casos cuando $i=j$ y más adelante se mostrará que algunas probabilidades serán 0.

-   La función de recompensa $R:\mathcal{S}\times \mathcal{A}\times \mathcal{S}\to[0,1]$, será $$
      R(S_i,a_k,S_j)=\left\{\begin{array}{ccc}
                   1 & \text{si} & S_j=G  \\
                   0 & o.c. &
              \end{array}\right.
      $$